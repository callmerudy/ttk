<html>

<head>

<style>
body { width: 820px; }
img { margin-top: 10pt; margin-left: 10pt; border: thin solid grey; display: block; }
.spacy li { margin-top: 10pt; margin-bottom: 10pt; }
.example { padding: 5pt; background: #eeeeee; border: thin dotted grey; }
.image { margin: 5pt; margin-left: 15pt; padding: 0pt; }
.indent { margin-left: 10pt; }
table { border: thin solid grey; border-collapse: collapse; width: 400pt; }
table td { border: thin solid grey; vertical-align: top; padding: 3pt; }
table.spacy { margin-top: 10pt; margin-bottom: 10pt; }
table.pythonclass { width: 400pt; }
table.pythonclass td { border-style: none; padding-left: 6pt; }
table.pythonclass td.name { font-weight: bold; border: thin solid grey; padding-left: 3pt;}
table.pythonclass td.attribute { }
</style>

</head>

<body>

<h1>Overview of the TARSQI Toolkit</h1>

<p>Marc Verhagen, December 2015<p>

<p>This document gives a high-level overview of the TARSQI Toolkit code.</p>


<h2>Top-level Processing</h2>

<p>The top-level processing chain is implemented in tarsqi.py in the Tarsqi
class, which upon initialization does the following:</p>

<ol class="spacy">

<li>Read the parameters. These are read from settings.txt but can also be
overridden on the command line invocation.

<li>Create a pipeline from the --pipeline parameter. A pipeline is a list of
pairs where each pair has the name of the component and the Python class that
implements it.

<li>Select the source parser. There are four parsers defined in
docmodel.parsers: DefaultParser, TimebankParser, ATEEParser and RTE3Parser. The
choice of parser is guided by the --genre parameter.

</ol>

<p>There is an instance of the Tarsqi class for each document processed. Actual
processing occurs through the Tarsqi.process() method, which does the following
things:</p>

<ol class="spacy">

<li>The class docmodel.source_parser.SourceParser parses the input file using
parse_file(filename) and returns an instance of docmodel.source_parser.SourceDoc
which includes two instance variables: text and tags.

<img src="images/sourceparser.png"/ height="75">

<table class="pythonclass indent spacy">
<tr>
  <td class="name" colspan="2">docmodel.source_parser.SourceDoc</td>
</tr>
<tr>
  <td class="attribute">text</td>
  <td>unicode string</td>
</tr>  
<tr>
  <td class="attribute">tags</td>
  <td>
    <table class="pythonclass">
      <tr>
	<td class="name" colspan="2">docmodel.source_parser.TagRepository</td>
      </tr>
      <tr>
	<td class="attribute">tags</td>
	<td>list of instances of docmodel.source_parser.Tag</td>
      </tr>  
      <tr>
	<td class="attribute">opening_tags</td>
	<td>dictionary of instances of docmodel.source_parser.Tag, indexed on
	opening offsets</td>
      </tr>  
      <tr>
	<td class="attribute">closing_tags</td>
	<td>dictionary of tag names, indexed on closing offsets and opening
	offsets</td>
      </tr>  
    </table>
  </td>
</tr>  
</table>

The input is assumed to be an XML file with inline XML tags and the SourceParser
turns it into the primary text data (text without tags) and a dictionary of
class TagRepository which has tags with character offsets pointing into the
primary data. Both instance variables are intended to be read-only. That is,
after the SourceDoc is created the primary data string never changes and tags
are not added to the TagRepository. Here is a minimal example as an
illustration:

<pre class="example indent">
&lt;?xml version="1.0" ?>
&lt;text>One &lt;noun>tag&lt;/noun> only.&lt;/text>
</pre>

For this text, the opening tags dictionary is as follows:

<pre class="example indent">
{1: [&lt;docmodel.source_parser.Tag instance at 0x107ac3638>], 
 5: [&lt;docmodel.source_parser.Tag instance at 0x107ac3518>]}
</pre>

Which indicates that there are opening tags at positions 1 and 5, and in both
cases there is only one tag at that offset. Instances of Tag contain the name of
the tag, its attributes and its begin and end offsets. The closing tags
dictionary for the above example is:

<pre class="example indent">
{8: {5: {u'noun': True}}, 14: {1: {u'text': True}}}
</pre>

This dictionary says that at character offset 8 we close a noun tag that was
opened at offset 5. The TagRepository class has convenience methods to access
tags.

<li>One of the parsers from docmodel.parsers is then used to take the SourceDoc
instance and create an instance of docmodel.document.TarsqiDocument.

<img src="images/defaultparser.png"/ height="75">

<table class="pythonclass indent spacy">
<tr>
  <td class="name" colspan="2">docmodel.document.TarsqiDocument</td>
</tr>
<tr>
  <td class="attribute">source</td>
  <td>an instance of docmodel.source_parser.SourceDoc</td>
</tr>
<tr>
  <td class="attribute">metadata</td>
  <td>a dictionary</td>
</tr>
<tr>
  <td class="attribute">parameters</td>
  <td>a dictionary</td>
</tr>
<tr>
  <td class="attribute">elements</td>
  <td>a list of instances of docmodel.document.TarsqiDocElement</td>
</tr>
</table>

The DefaultParser does some minimal processing of the source document,
extracting a document creation time and putting it in the metadata dictionary
under the 'dct' key and splitting the document into paragraphs and putting each
paragraph in the elements list. In the current implimentation, all elements are
instances of TarsqiDocParagraph, a subclass of TarsqiDocElement, which has the
following structure:

<table class="pythonclass indent spacy">
<tr>
  <td class="name" colspan="2">docmodel.document.TarsqiDocElement</td>
</tr>
<tr>
  <td class="attribute">doc</td>
  <td>an instance of docmodel.document.TarsqiDocument</td>
</tr>  
<tr>
  <td class="attribute">begin</td>
  <td>the beginning offset in the SourceDoc in doc.source</td>
</tr>
<tr>
  <td class="attribute">end</td>
  <td>the ending offset in the SourceDoc in doc.source</td>
</tr>
<tr>
  <td class="attribute">source_tags</td>
  <td>an instance of docmodel.source_parser.TagRepository, containing a subset
  of the tags in the source document, namely those that span part or all of the
  paragraph</td>
</tr>
<tr>
  <td class="attribute">tarsqi_tags</td>
  <td>an instance of docmodel.source_parser.TagRepository, initially empty</td>
</tr>
</table>

In the future, other sub classes of TarsqiDocElement will be added (for example
SectionHeader) and perhaps theelements list will come to implement a hierarchy.

<li>Add the parameters from the settings.txt file and the command line options
to the TarsqiDocument. This fills in the parameters dictionary.

<li>Apply components as specified in the pipeline. Recall that on initialization
the Tarsqi class creates a pipeline of components from the user's --pipeline
option. If we had used a command line invocation like

<pre class="example indent">
$ python tarsqi.py --pipeline=PREPROCESSOR,GUTIME,EVITA in.xml out.xml
</pre>

then the pipeline as stored in the Tarsqi instance would be

<pre class="example indent">
[('PREPROCESSOR', &lt;class components.preprocessing.wrapper.PreprocessorWrapper at 0x10514a668>), 
 ('GUTIME', &lt;class components.gutime.wrapper.GUTimeWrapper at 0x1051c36d0>), 
 ('EVITA', &lt;class components.evita.wrapper.EvitaWrapper at 0x1051c3ce8>)]
</pre>

The code for all components is wrapped in special wrapper classes. All that the
wrappers are required to have are (1) an initialization method that takes the
TarsqiDocument as its sole argument and (2) a process() method which has the
side effect of changing the TarsqiDocument instance. Components update the
TarsqiDocument by updating the TagRepository instances inside the
TarsqiDocElement instances in the elements list. In some cases, another data
structure is updated first and then the results are exported to the
TarsqiDocElements.

<li>Print results. The Tarsqi class does this by asking the TarsqiDocument to
print the source string and all tags to a document, which in turn is done by
retrieving the source and the source tags from the SourceDoc instance and the
added Tarsqi tags from the TagRepository in the tarsqi_tags attributes on
TarsqiDocElements. The output is written to one file with both the primary data
and the tags. For example, take the example input below.

<pre class="example indent">
&lt;?xml version="1.0" ?>
&lt;text>He sleeps on Friday.&lt;/text>
</pre>

And suppose we have a pipeline that includes the preprocessor, GUTime and
Evita. Then the output will be:

<pre class="example indent">
&lt;ttk>
&lt;text>
He sleeps on Friday.
&lt;/text>
&lt;source_tags>
  &lt;text id="1" begin="1" end="21" />
&lt;/source_tags>
&lt;ttk_tags>
  &lt;TIMEX3 tid="t0" type="DATE" value="20160105" functionInDocument="CREATION_TIME"/>
  &lt;doc_element type="TarsqiDocParagraph" begin="1" end="21">
    &lt;lex id="l1" begin="1" end="3" lemma="he" pos="PP" />
    &lt;NG id="c1" begin="1" end="3" targets="l1 l1" />
    &lt;lex id="l2" begin="4" end="10" lemma="sleep" pos="VBZ" />
    &lt;VG id="c2" begin="4" end="10" targets="l2 l2" />
    &lt;lex id="l3" begin="11" end="13" lemma="on" pos="IN" />
    &lt;lex id="l4" begin="14" end="20" lemma="Friday" pos="NNP" />
    &lt;NG id="c3" begin="14" end="20" targets="l4 l4" />
    &lt;lex id="l5" begin="20" end="21" lemma="." pos="." />
    &lt;s id="s1" begin="1" end="21" targets="l1 l5" />
    &lt;TIMEX3 id="1" begin="14" end="20" type="DATE" value="" />
    &lt;EVENT id="2" begin="4" end="10" polarity="POS" pos="VERB" eiid="ei1"
         tense="PRESENT" eid="e1" aspect="NONE" class="OCCURRENCE" />
  &lt;/doc_element>
&lt;/ttk_tags>
&lt;/ttk>
</pre>

Note that the EVENT tag will actually be printed on one line only, it is split
over two lines here for readability.

</ol>


<h2>The Preprocessor</h2>

<p>The PreprocessorWrapper loops through the TarsiDocElements. For each element,
it extracts the source text, runs the tokenizer, tagger and chunker on that text
and then exports the results back to the TarsqiDocElements.</p>

<img src="images/preprocessing.png" height="250"/>

<p>The tokenizer copies the text from the TarsqiDocParagraph (which actually
does not hold the text itself but it has the character offsets in the SourceDoc
and a reference to the SourceDoc) and it returns a list of pairs, where each
pair is either ('&lt;s>', None) for sentence boundaries or a pair of a string
and a TokenizedLex instance, which has instance variables begin, end and
text:</p>

<pre class="example indent">
[('&lt;s>', None),
 (u'Fido', &lt;components.preprocessing.tokenizer.TokenizedLex instance at 0x110844998>),
 (u'barks', &lt;components.preprocessing.tokenizer.TokenizedLex instance at 0x110844ab8>),
 (u'.', &lt;components.preprocessing.tokenizer.TokenizedLex instance at 0x110844b48>)]
</pre>

<p>Since the tokenizer runs in isolation on the text of an element, it assignes
offsets starting at 0 to the text. The PreprocessWrappers adjusts these so that
the offsets point into the correct spot in the full text source of the
document.</p>

<p>The tagger is then fed a vertical string consisting of the first element of
all pairs (the s tag or a string):</p>

<pre class="example indent">
&lt;s>
Fido
barks
.
</pre>

The tagger returns a list with as many elements as lines, where each element is
either an s tag or a tab-separated triple of string, part-of-speech tag and
lemma:</p>

<pre class="example indent">
['&lt;s>', 
 'Fido\tNP\tFido', 
 'barks\tVVZ\tbark', 
 '.\tSENT\t.']
</pre>

<p>The PreprocessorWrapper then takes this list and merges it with the list of
pairs that came out of the tokenizer and creates the following structure:</p>

<pre class="example indent">
[[('Fido', 'NNP', 'Fido', 1, 5), 
  ('barks', 'VBZ', 'bark', 6, 11), 
  ('.', '.', '.', 11, 12)]]
</pre>

<p>Note that the s tags have disappeared and that instead we now have a list of
sublists, with one sublist for each sentence. Another thing that happens at this
transformation stage is some normalization of tag names. The chunker adds NG and
VG tags to the sublists.</p>

<pre class="example indent">
[['&lt;NG>', ('Fido', 'NNP', 'Fido', 1, 5), '&lt;/NG>', 
  '&lt;VG>', ('barks', 'VBZ', 'bark', 6, 11), '&lt;/VG>', 
  ('.', '.', '.', 11, 12)]]
</pre>

<p>Finally, the information in this data structure is exported to the
tarsqi_tags TagRepository on the TarsqiDocElement, where the opening_tags and
closing_tags dictionaries now look as follows:</p>

<pre class="example indent">
{ 1: [&lt;docmodel.source_parser.Tag instance at 0x1033c9830>, 
      &lt;docmodel.source_parser.Tag instance at 0x1033c98c0>, 
      &lt;docmodel.source_parser.Tag instance at 0x1033c9e18>],
  6: [&lt;docmodel.source_parser.Tag instance at 0x1033c9a70>, 
      &lt;docmodel.source_parser.Tag instance at 0x1033c9cf8>],
 11: [&lt;docmodel.source_parser.Tag instance at 0x1033c9ef0>] }
</pre>

<pre class="example indent">
{  5: { 1: {'lex': True, 'NG': True}}
  11: { 6: {'lex': True, 'VG': True}}, 
  12: { 1: {'s': True}, 
       11: {'lex': True}} }
</pre>


<h2>GUTime</h2>

<p>The GUTimeWrapper takes the content of all TarsqiDocElements in the
TarsqiDocument and creates the input needed by
code/components/gutime/TimeTag.pl, which is the wrapper around TempEx.pm in the
same directory. The input required by TimeTag.pl is a file with content as follows:

<pre class="example indent">
&lt;DOC>
&lt;DATE>20160102&lt;/DATE>
&lt;s>
   &lt;lex id="l1" begin="1" end="5" pos="NNP">Fido&lt;/lex>
   &lt;lex id="l2" begin="6" end="11" pos="NNS">barks&lt;/lex>
   &lt;lex id="l3" begin="12" end="14" pos="IN">on&lt;/lex>
   &lt;lex id="l4" begin="15" end="21" pos="NNP">Monday&lt;/lex>
   &lt;lex id="l5" begin="21" end="22" pos=".">.&lt;/lex>
&lt;/s>
&lt;/DOC>
</pre>

<p>The DOC root and the DATE tag are required, the latter being the way that the
DCT is handed to GUTime. Otherwise, only s and lex tags are allowed. GUTime does
not require the lex tags to have the begin and end attributes, but it is okay
for them to be there. Any kind of spacing between the tags is allowed. The
wrapper creates the above file in a temporary data directory code/data/tmp
(which is emptied at the beginning of each tarsqi.py invocation) and then uses
the Python subprocess module to run the Perl script. The output is put in the
same temporary directory and is exactly like the input except that TIMEX3 tags
are added:</p>

<pre class="example indent">
&lt;DOC>
&lt;DATE>&lt;TIMEX3 VAL="20160102">20160102&lt;/TIMEX3>&lt;/DATE>
&lt;s>
   &lt;lex id="l1" begin="1" end="5" pos="NNP">Fido&lt;/lex>
   &lt;lex id="l2" begin="6" end="11" pos="NNS">barks&lt;/lex>
   &lt;lex id="l3" begin="12" end="14" pos="IN">on&lt;/lex>
   &lt;TIMEX3 tid="t1" TYPE="DATE">&lt;lex id="l4" begin="15" end="21" pos="NNP">Monday&lt;/lex>&lt;/TIMEX3>
   &lt;lex id="l5" begin="21" end="22" pos=".">.&lt;/lex>
&lt;/s>
&lt;/DOC>
</pre>

<p>Similar to what happened with the preprocessor results, the new TIMEX3 tags
are exported to the tarsqi_tags TagRepository on the TarsqiDocElement.</p>

<h2>Evita</h2>

<p>The EvitaWrapper class is handed the TarsqiDocument and loops over all
TarsqiDocElements in it, creating an Evita instance for all of them and then
procesing the element. The Evita instance has slots for the TarsqiDocument, the
TarsqiDocElement and a TarsqiTree instance which contains a document tree for the
TarsqiDocElement that is being processed.</p>

<table class="pythonclass indent spacy">
<tr>
  <td class="name" colspan="2">components.evita.main.Evita</td>
</tr>
<tr>
  <td class="attribute">tarsqidoc</td>
  <td>an instance of docmodel.document.TarsqiDocument</td>
</tr>
<tr>
  <td class="attribute">docelement</td>
  <td>an instance of docmodel.document.TarsqDocElement or subclass thereof, the
  element of the TarsqiDocument that is being processed by Evita</td>
</tr>
<tr>
  <td class="attribute">doctree</td>
  <td>
    <table class="pythonclass">
      <tr>
	<td class="name" colspan="2">components.common_modules.document.TarsqiTree</td>
      </tr>
      <tr>
	<td class="attribute">tarsqidoc</td>
	<td>an instance of docmodel.document.TarsqiDocument</td>
      </tr>
      <tr>
	<td class="attribute">docelement</td>
	<td>the TarsqDocElement that the document tree is created for</td>
      </tr>
      <tr>
	<td class="attribute">dtrs</td>
	<td>a list of daughters, typically instances of Sentence</td>
      </tr>
    </table>
  </td>
</tr>
</table>

<p>The Document instance itself knows what TarsqiDocument it belongs to and what
TarsqiDocElement it was created for. It has a list of daughters and some other
attributes that are ignored here because they are not used by Evita.</p>


<pre class="example indent">
&lt;NounChunk position=0 checkedEvents=False event=None eid=None>
  &lt;Token position=0 pos=DT text=The>
  &lt;Token position=1 pos=NN text=dog>
&lt;VerbChunk position=1 checkedEvents=False event=None eid=None>
  &lt;Token position=0 pos=VBD text=barked>
&lt;NounChunk position=2 checkedEvents=False event=None eid=None>
  &lt;TIMEX3 tid=t1 type=DATE value=20160103>
    &lt;Token position=0 pos=NN text=yesterday>
&lt;Token position=3 pos=. text=.>
</pre>


<h2>Slinket</h2>

<table class="pythonclass indent spacy">
<tr>
  <td class="name" colspan="2">components.common_modules.document.TarsqiTree</td>
</tr>
<tr>
  <td class="attribute">tarsqidoc</td>
  <td>an instance of docmodel.document.TarsqiDocument</td>
</tr>
<tr>
  <td class="attribute">docelement</td>
  <td>the TarsqiDocElement that the tree is created for</td>
</tr>
 <tr>
  <td class="attribute">dtrs</td>
  <td>a list of daughters, typically instances of Sentence</td>
</tr>
<tr>
  <td class="attribute">events</td>
  <td>a dictionary containing events for the TarsqiDocElement that were found by
  Evita, it is created by SLinket by collecting events and their attributes from
  the document tree in dtrs</td>
</tr>
<tr>
  <td class="attribute">alink_list</td>
  <td>a list of AlinkTags</td>
</tr>
<tr>
  <td class="attribute">slink_list</td>
  <td>a list of SlinkTags</td>
</tr>
<tr>
  <td class="attribute">tlink_list</td>
  <td>a list of TlinkTags</td>
</tr>
</table>


<h2>Tags added by the Tarsqi toolkit</h2>

<p>All Tarsqi tags added by the system have identifiers that are unique to the document
and the tag type. The identifiers consist of a tag-specific prefix and an integer. The
prefixes and the tags they go with are listed in the table below.</p>

<p>Some identifiers are introduces with an attribute "id", but the TimeML tags
have special identifier attributes: tid, eid, eiid, and lid.</p>

<table class="indent">
<tr>
  <td>l
  <td>&lt;lex&gt;
  <td>The lexical tokens from the base segmentation. Refer to character offsets.
<tr>
  <td>c
  <td>&lt;ng&gt;, &lt;vg&gt;
  <td>Chunks. Refer to character offsets and lex ids.
<tr>
  <td>s  
  <td>&lt;s&gt;
  <td>Sentence boundaries. Refer to character offsets and lex ids.
<tr>
  <td>t  
  <td>&lt;timex3&gt;
  <td>BTime timex tags.
<tr>
  <td>e  
  <td>&lt;event&gt;
  <td>Evita event tags, notice the absence of the depricated makeinstance tag.
<tr>
  <td>al  
  <td>&lt;alink&gt;
  <td rowspan="3" valign="top">The three relation tags. These can only refer to event ids or timex ids.
<tr>
  <td>sl
  <td>&lt;slink&gt;
<tr>
  <td>tl
  <td>&lt;tlink&gt;
</table>


</body>
</html>
